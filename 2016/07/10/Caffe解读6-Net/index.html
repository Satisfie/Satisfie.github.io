<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="learn, think" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="简介Net将各个层组成了一个无回路有向图。在解读Net的过程中，同样需要先看一下其在caffe.proto中的定义message NetParameter以及对应生成的hpp和cpp。然后主要是net.hpp和net.cpp。
message NetParameter
optional string name: 网络对应的名字
repeated string input: 网络输入的blobs
r">
<meta property="og:type" content="article">
<meta property="og:title" content="Caffe解读6 -- Net">
<meta property="og:url" content="http://yoursite.com/2016/07/10/Caffe解读6-Net/index.html">
<meta property="og:site_name" content="Keson's blog">
<meta property="og:description" content="简介Net将各个层组成了一个无回路有向图。在解读Net的过程中，同样需要先看一下其在caffe.proto中的定义message NetParameter以及对应生成的hpp和cpp。然后主要是net.hpp和net.cpp。
message NetParameter
optional string name: 网络对应的名字
repeated string input: 网络输入的blobs
r">
<meta property="og:updated_time" content="2017-03-08T08:59:52.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Caffe解读6 -- Net">
<meta name="twitter:description" content="简介Net将各个层组成了一个无回路有向图。在解读Net的过程中，同样需要先看一下其在caffe.proto中的定义message NetParameter以及对应生成的hpp和cpp。然后主要是net.hpp和net.cpp。
message NetParameter
optional string name: 网络对应的名字
repeated string input: 网络输入的blobs
r">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2016/07/10/Caffe解读6-Net/"/>





  <title> Caffe解读6 -- Net | Keson's blog </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
<!-- hexo-inject:begin --><!-- hexo-inject:end --><script>
  window.fbAsyncInit = function() {
    FB.init({
      appId      : '',
      xfbml      : true,
      version    : 'v2.6'
    });
  };

  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "//connect.facebook.net/zh_Hans/sdk.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>











  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Keson's blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/07/10/Caffe解读6-Net/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="John Doe">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.png">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Keson's blog">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Keson's blog" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Caffe解读6 -- Net
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time title="Post created" itemprop="dateCreated datePublished" datetime="2016-07-10T12:56:33+08:00">
              2016-07-10
            </time>

            &nbsp;|&nbsp;

            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-check-o"></i>
            </span>
            <time title="Post modified" itemprop="dateModified" datetime="2017-03-08T16:59:52+08:00">
              2017-03-08
            </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/07/10/Caffe解读6-Net/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count fb-comments-count" data-href="http://yoursite.com/2016/07/10/Caffe解读6-Net/" itemprop="commentCount">0</span> comments
                </a>
              </span>
            
          

          



          
          
             <span id="/2016/07/10/Caffe解读6-Net/" class="leancloud_visitors" data-flag-title="Caffe解读6 -- Net">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
              &nbsp; | &nbsp;
              <span class="page-pv"><i class="fa fa-file-o"></i>
              <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
              </span>
          
          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><code>Net</code>将各个层组成了一个无回路有向图。在解读<code>Net</code>的过程中，同样需要先看一下其在<code>caffe.proto</code>中的定义<code>message NetParameter</code>以及对应生成的hpp和cpp。然后主要是<code>net.hpp</code>和<code>net.cpp</code>。</p>
<h1 id="message-NetParameter"><a href="#message-NetParameter" class="headerlink" title="message NetParameter"></a><code>message NetParameter</code></h1><ul>
<li><code>optional string name:</code> 网络对应的名字</li>
<li><code>repeated string input:</code> 网络输入的blobs</li>
<li><code>repeated BlobShape input_shape:</code>网络输入blobs对应的shape</li>
<li><code>repeated int32 input_dim:</code>输入维度</li>
<li><code>optional bool force_backward:</code>是否强制回传，默认为false,根据网络结构和学习率进行回传</li>
<li><p><code>optional NetState state:</code> 包括网络的<code>phase</code>,<code>level</code>和<code>stage</code></p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">message NetState &#123;</div><div class="line">	optional Phase phase = <span class="number">1</span> [<span class="keyword">default</span> = TEST];</div><div class="line"> 	optional int32 level = <span class="number">2</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line"> 	repeated <span class="built_in">string</span> stage = <span class="number">3</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p><code>optional bool debug_info:</code>决定是否打印debug信息</p>
</li>
<li><code>repeated LayerParameter layer:</code>定义网络中每层的参数</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">message NetParameter &#123;</div><div class="line">  optional <span class="built_in">string</span> name = <span class="number">1</span>; <span class="comment">// consider giving the network a name</span></div><div class="line">  <span class="comment">// DEPRECATED. See InputParameter. The input blobs to the network.</span></div><div class="line">  repeated <span class="built_in">string</span> input = <span class="number">3</span>;</div><div class="line">  <span class="comment">// DEPRECATED. See InputParameter. The shape of the input blobs.</span></div><div class="line">  repeated BlobShape input_shape = <span class="number">8</span>;</div><div class="line"></div><div class="line">  <span class="comment">// 4D input dimensions -- deprecated.  Use "input_shape" instead.</span></div><div class="line">  <span class="comment">// If specified, for each input blob there should be four</span></div><div class="line">  <span class="comment">// values specifying the num, channels, height and width of the input blob.</span></div><div class="line">  <span class="comment">// Thus, there should be a total of (4 * #input) numbers.</span></div><div class="line">  repeated int32 input_dim = <span class="number">4</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Whether the network will force every layer to carry out backward operation.</span></div><div class="line">  <span class="comment">// If set False, then whether to carry out backward is determined</span></div><div class="line">  <span class="comment">// automatically according to the net structure and learning rates.</span></div><div class="line">  optional <span class="keyword">bool</span> force_backward = <span class="number">5</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line">  <span class="comment">// The current "state" of the network, including the phase, level, and stage.</span></div><div class="line">  <span class="comment">// Some layers may be included/excluded depending on this state and the states</span></div><div class="line">  <span class="comment">// specified in the layers' include and exclude fields.</span></div><div class="line">  optional NetState state = <span class="number">6</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Print debugging information about results while running Net::Forward,</span></div><div class="line">  <span class="comment">// Net::Backward, and Net::Update.</span></div><div class="line">  optional <span class="keyword">bool</span> debug_info = <span class="number">7</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line"></div><div class="line">  <span class="comment">// The layers that make up the net.  Each of their configurations, including</span></div><div class="line">  <span class="comment">// connectivity and behavior, is specified as a LayerParameter.</span></div><div class="line">  repeated LayerParameter layer = <span class="number">100</span>;  <span class="comment">// ID 100 so layers are printed last.</span></div><div class="line"></div><div class="line">  <span class="comment">// DEPRECATED: use 'layer' instead.</span></div><div class="line">  repeated V1LayerParameter layers = <span class="number">2</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><p><code>net.hpp</code> 和 <code>net.cpp</code></p>
<h2 id="protected变量"><a href="#protected变量" class="headerlink" title="protected变量"></a>protected变量</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/// @brief The network name</span></div><div class="line"><span class="built_in">string</span> name_;  <span class="comment">//网络对应的名字</span></div><div class="line"><span class="comment">/// @brief The phase: TRAIN or TEST</span></div><div class="line">Phase phase_;  <span class="comment">//对应的阶段TRAIN或者TEST</span></div><div class="line"><span class="comment">/// @brief Individual layers in the net</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;Layer&lt;Dtype&gt; &gt; &gt; layers_; <span class="comment">//定义各层</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; layer_names_; <span class="comment">//各层的名字</span></div><div class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt; layer_names_index_; <span class="comment">//各层对应的名字和index</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; layer_need_backward_; <span class="comment">//各层是否需要回传</span></div><div class="line"></div><div class="line"><span class="comment">/// @brief the blobs storing intermediate results between the layer.</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;Blob&lt;Dtype&gt; &gt; &gt; blobs_; <span class="comment">//各层之间存储中间结果</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; blob_names_; <span class="comment">//各个blob的名字</span></div><div class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt; blob_names_index_; <span class="comment">//各个blob名字及对应的index</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; blob_need_backward_;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">/// bottom_vecs stores the vectors containing the input for each layer.</span></div><div class="line"><span class="comment">/// They don't actually host the blobs (blobs_ does), so we simply store</span></div><div class="line"><span class="comment">/// pointers.</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; &gt; bottom_vecs_; <span class="comment">//存放各个层的输入，vector的vector，每层的输入是一个vector&lt;Blob&lt;Dtype&gt;*&gt;</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; bottom_id_vecs_; <span class="comment">//存放各个层的输入blob对应的id</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; &gt; bottom_need_backward_;</div><div class="line"></div><div class="line"><span class="comment">/// top_vecs stores the vectors containing the output for each layer</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; &gt; top_vecs_; <span class="comment">//存放各个层的输出，每个层是一个vector&lt;Blob&lt;Dtype&gt;*&gt;</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; top_id_vecs_; <span class="comment">//存放各个层输出的blob的id</span></div><div class="line"></div><div class="line"><span class="comment">/// Vector of weight in the loss (or objective) function of each net blob,</span></div><div class="line"><span class="comment">/// indexed by blob_id.</span></div><div class="line"><span class="built_in">vector</span>&lt;Dtype&gt; blob_loss_weights_;  <span class="comment">//loss blob的权重</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; param_id_vecs_; <span class="comment">// </span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; param_owners_;</div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; param_display_names_;</div><div class="line"><span class="built_in">vector</span>&lt;pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; &gt; param_layer_indices_;</div><div class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt; param_names_index_;</div><div class="line"></div><div class="line"><span class="comment">/// blob indices for the input and the output of the net</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; net_input_blob_indices_;   <span class="comment">//网络输入blob的index</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; net_output_blob_indices_;  <span class="comment">//网络输出blob的index</span></div><div class="line"><span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; net_input_blobs_; <span class="comment">//网络输入的blobs,存放的是指针</span></div><div class="line"><span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; net_output_blobs_;<span class="comment">//网络输出的blobs，存放的是指针</span></div><div class="line"></div><div class="line"><span class="comment">/// The parameters in the network.</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;Blob&lt;Dtype&gt; &gt; &gt; params_; <span class="comment">//网络的参数</span></div><div class="line"><span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; learnable_params_; <span class="comment">//网络学习参数</span></div><div class="line"><span class="comment">/**</span></div><div class="line"> * The mapping from params_ -&gt; learnable_params_: we have</div><div class="line"> * learnable_param_ids_.size() == params_.size(),</div><div class="line"> * and learnable_params_[learnable_param_ids_[i]] == params_[i].get()</div><div class="line"> * if and only if params_[i] is an "owner"; otherwise, params_[i] is a sharer</div><div class="line"> * and learnable_params_[learnable_param_ids_[i]] gives its owner.</div><div class="line"> */</div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; learnable_param_ids_;</div><div class="line"><span class="comment">/// the learning rate multipliers for learnable_params_</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt; params_lr_; <span class="comment">//参数的学习率</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; has_params_lr_; <span class="comment">//是否有学习参数</span></div><div class="line"><span class="comment">/// the weight decay multipliers for learnable_params_</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt; params_weight_decay_; <span class="comment">//权重衰减</span></div><div class="line"><span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; has_params_decay_;     <span class="comment">//是否有权重衰减</span></div><div class="line"><span class="comment">/// The bytes of memory used by this net</span></div><div class="line"><span class="keyword">size_t</span> memory_used_;    <span class="comment">//网络使用的内存</span></div><div class="line"><span class="comment">/// Whether to compute and display debug info for the net.</span></div><div class="line"><span class="keyword">bool</span> debug_info_;</div><div class="line"><span class="comment">/// The root net that actually holds the shared layers in data parallelism</span></div><div class="line"><span class="keyword">const</span> Net* <span class="keyword">const</span> root_net_;</div><div class="line">DISABLE_COPY_AND_ASSIGN(Net);</div></pre></td></tr></table></figure>
<h2 id="protected-方法"><a href="#protected-方法" class="headerlink" title="protected 方法"></a>protected 方法</h2><ul>
<li><code>AppendTop():</code>    给网络增加新的top blob</li>
<li><code>AppendBottom():</code> 给网络增加新的bottom blob</li>
<li><code>AppendParam():</code>  给网络增加新的parameter blob</li>
<li><code>ForwardDebugInfo():</code>  前向时打印debug信息</li>
<li><code>BackwardDebugInfo():</code> 反向传播时打印debug信息</li>
<li><code>UpdataDebugInfo():</code>   更新时打印debug信息</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Helpers for Init.</span></div><div class="line"><span class="comment">/// @brief Append a new top blob to the net.</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">AppendTop</span><span class="params">(<span class="keyword">const</span> NetParameter&amp; param, <span class="keyword">const</span> <span class="keyword">int</span> layer_id,</span></span></div><div class="line">               <span class="keyword">const</span> <span class="keyword">int</span> top_id, <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt;* available_blobs,</div><div class="line">               <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;* blob_name_to_idx);</div><div class="line"><span class="comment">/// @brief Append a new bottom blob to the net.</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">AppendBottom</span><span class="params">(<span class="keyword">const</span> NetParameter&amp; param, <span class="keyword">const</span> <span class="keyword">int</span> layer_id,</span></span></div><div class="line">                 <span class="keyword">const</span> <span class="keyword">int</span> bottom_id, <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt;* available_blobs,</div><div class="line">                 <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;* blob_name_to_idx);</div><div class="line"><span class="comment">/// @brief Append a new parameter blob to the net.</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">AppendParam</span><span class="params">(<span class="keyword">const</span> NetParameter&amp; param, <span class="keyword">const</span> <span class="keyword">int</span> layer_id,</span></span></div><div class="line">                 <span class="keyword">const</span> <span class="keyword">int</span> param_id);</div><div class="line"></div><div class="line"><span class="comment">/// @brief Helper for displaying debug info in Forward.</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">ForwardDebugInfo</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> layer_id)</span></span>;</div><div class="line"><span class="comment">/// @brief Helper for displaying debug info in Backward.</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">BackwardDebugInfo</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> layer_id)</span></span>;</div><div class="line"><span class="comment">/// @brief Helper for displaying debug info in Update.</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">UpdateDebugInfo</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> param_id)</span></span>;</div></pre></td></tr></table></figure>
<h3 id="AppendTop"><a href="#AppendTop" class="headerlink" title="AppendTop()"></a><code>AppendTop()</code></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Helper for Net::Init: add a new top blob to the net.</span></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::AppendTop(<span class="keyword">const</span> NetParameter&amp; param, <span class="keyword">const</span> <span class="keyword">int</span> layer_id,</div><div class="line">                           <span class="keyword">const</span> <span class="keyword">int</span> top_id, <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt;* available_blobs,</div><div class="line">                           <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;* blob_name_to_idx) &#123;</div><div class="line">  <span class="built_in">shared_ptr</span>&lt;LayerParameter&gt; layer_param(</div><div class="line">      <span class="keyword">new</span> LayerParameter(param.layer(layer_id)));</div><div class="line">  <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name = (layer_param-&gt;top_size() &gt; top_id) ?</div><div class="line">      layer_param-&gt;top(top_id) : <span class="string">"(automatic)"</span>;</div><div class="line">  <span class="comment">// Check if we are doing in-place computation</span></div><div class="line">  <span class="keyword">if</span> (blob_name_to_idx &amp;&amp; layer_param-&gt;bottom_size() &gt; top_id &amp;&amp;</div><div class="line">      blob_name == layer_param-&gt;bottom(top_id)) &#123;</div><div class="line">    <span class="comment">// In-place computation</span></div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; layer_param-&gt;name() &lt;&lt; <span class="string">" -&gt; "</span> &lt;&lt; blob_name &lt;&lt; <span class="string">" (in-place)"</span>;</div><div class="line">    top_vecs_[layer_id].push_back(blobs_[(*blob_name_to_idx)[blob_name]].get());</div><div class="line">    top_id_vecs_[layer_id].push_back((*blob_name_to_idx)[blob_name]);</div><div class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (blob_name_to_idx &amp;&amp;</div><div class="line">             blob_name_to_idx-&gt;find(blob_name) != blob_name_to_idx-&gt;end()) &#123;</div><div class="line">    <span class="comment">// If we are not doing in-place computation but have duplicated blobs,</span></div><div class="line">    <span class="comment">// raise an error.</span></div><div class="line">    LOG(FATAL) &lt;&lt; <span class="string">"Top blob '"</span> &lt;&lt; blob_name</div><div class="line">               &lt;&lt; <span class="string">"' produced by multiple sources."</span>;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="comment">// Normal output.</span></div><div class="line">    <span class="keyword">if</span> (Caffe::root_solver()) &#123;</div><div class="line">      LOG(INFO) &lt;&lt; layer_param-&gt;name() &lt;&lt; <span class="string">" -&gt; "</span> &lt;&lt; blob_name;</div><div class="line">    &#125;</div><div class="line">    <span class="built_in">shared_ptr</span>&lt;Blob&lt;Dtype&gt; &gt; blob_pointer(<span class="keyword">new</span> Blob&lt;Dtype&gt;());</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> blob_id = blobs_.size();</div><div class="line">    blobs_.push_back(blob_pointer);</div><div class="line">    blob_names_.push_back(blob_name);</div><div class="line">    blob_need_backward_.push_back(<span class="literal">false</span>);</div><div class="line">    <span class="keyword">if</span> (blob_name_to_idx) &#123; (*blob_name_to_idx)[blob_name] = blob_id; &#125;</div><div class="line">    top_id_vecs_[layer_id].push_back(blob_id);</div><div class="line">    top_vecs_[layer_id].push_back(blob_pointer.get());</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">if</span> (available_blobs) &#123; available_blobs-&gt;insert(blob_name); &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="AppendBottom"><a href="#AppendBottom" class="headerlink" title="AppendBottom()"></a><code>AppendBottom()</code></h3><p>这个函数不难，我们来分析一下，主要参数包括：</p>
<ul>
<li><code>param:</code> <code>NetParameter</code>类型的引用</li>
<li><code>layer_id:</code> 需要添加bottom 的layer的id</li>
<li><code>bottom_id:</code> bottom对应的id</li>
<li><code>availabel_blobs：</code> 可用的blobs, vector<string></string></li>
<li><code>blob_name_to_idx:</code> blob名字和idx对应的map</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Helper for Net::Init: add a new bottom blob to the net.</span></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">int</span> Net&lt;Dtype&gt;::AppendBottom(<span class="keyword">const</span> NetParameter&amp; param, <span class="keyword">const</span> <span class="keyword">int</span> layer_id,</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> bottom_id, <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt;* available_blobs,</div><div class="line">    <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;* blob_name_to_idx) &#123;</div><div class="line">  <span class="keyword">const</span> LayerParameter&amp; layer_param = param.layer(layer_id);</div><div class="line">  <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name = layer_param.bottom(bottom_id);</div><div class="line">  <span class="keyword">if</span> (available_blobs-&gt;find(blob_name) == available_blobs-&gt;end()) &#123;</div><div class="line">    LOG(FATAL) &lt;&lt; <span class="string">"Unknown bottom blob '"</span> &lt;&lt; blob_name &lt;&lt; <span class="string">"' (layer '"</span></div><div class="line">               &lt;&lt; layer_param.name() &lt;&lt; <span class="string">"', bottom index "</span> &lt;&lt; bottom_id &lt;&lt; <span class="string">")"</span>;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">const</span> <span class="keyword">int</span> blob_id = (*blob_name_to_idx)[blob_name];</div><div class="line">  LOG_IF(INFO, Caffe::root_solver())</div><div class="line">      &lt;&lt; layer_names_[layer_id] &lt;&lt; <span class="string">" &lt;- "</span> &lt;&lt; blob_name;</div><div class="line">  bottom_vecs_[layer_id].push_back(blobs_[blob_id].get());</div><div class="line">  bottom_id_vecs_[layer_id].push_back(blob_id);</div><div class="line">  available_blobs-&gt;erase(blob_name);</div><div class="line">  <span class="keyword">bool</span> need_backward = blob_need_backward_[blob_id];</div><div class="line">  <span class="comment">// Check if the backpropagation on bottom_id should be skipped</span></div><div class="line">  <span class="keyword">if</span> (layer_param.propagate_down_size() &gt; <span class="number">0</span>) &#123;</div><div class="line">    need_backward = layer_param.propagate_down(bottom_id);</div><div class="line">  &#125;</div><div class="line">  bottom_need_backward_[layer_id].push_back(need_backward);</div><div class="line">  <span class="keyword">return</span> blob_id;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="AppendParam"><a href="#AppendParam" class="headerlink" title="AppendParam()"></a><code>AppendParam()</code></h3><p>在网络中增加层对应的bottom的 param</p>
<p>参数</p>
<ul>
<li><code>param:</code> <code>NetParameter</code>引用</li>
<li><code>layer_id:</code> 对应层的id</li>
<li><code>param_id:</code> param对应的id</li>
</ul>
<h2 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h2><p>在构造函数里最主要的是调用了<code>Init()</code>函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line">Net&lt;Dtype&gt;::Net(<span class="keyword">const</span> NetParameter&amp; param, <span class="keyword">const</span> Net* root_net)</div><div class="line">    : root_net_(root_net) &#123;</div><div class="line">  Init(param);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line">Net&lt;Dtype&gt;::Net(<span class="keyword">const</span> <span class="built_in">string</span>&amp; param_file, Phase phase,</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> level, <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;* stages,</div><div class="line">    <span class="keyword">const</span> Net* root_net)</div><div class="line">    : root_net_(root_net) &#123;</div><div class="line">  NetParameter param;</div><div class="line">  ReadNetParamsFromTextFileOrDie(param_file, &amp;param);</div><div class="line">  <span class="comment">// Set phase, stages and level</span></div><div class="line">  param.mutable_state()-&gt;set_phase(phase);</div><div class="line">  <span class="keyword">if</span> (stages != <span class="literal">NULL</span>) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; stages-&gt;size(); i++) &#123;</div><div class="line">      param.mutable_state()-&gt;add_stage((*stages)[i]);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  param.mutable_state()-&gt;set_level(level);</div><div class="line">  Init(param);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="FilterNet-函数"><a href="#FilterNet-函数" class="headerlink" title="FilterNet()函数"></a><code>FilterNet()</code>函数</h2><p>使用其他param 来初始化本网络的<code>param</code>,其中考虑了include 和exclude 的状态。即滤出一些不包含状态下的层</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">template &lt;typename Dtype&gt;</div><div class="line">void Net&lt;Dtype&gt;::FilterNet(const NetParameter&amp; param,</div><div class="line">    NetParameter* param_filtered) &#123;</div><div class="line">  NetState net_state(param.state());</div><div class="line">  param_filtered-&gt;CopyFrom(param);</div><div class="line">  param_filtered-&gt;clear_layer();</div><div class="line">  for (int i = 0; i &lt; param.layer_size(); ++i) &#123;</div><div class="line">    const LayerParameter&amp; layer_param = param.layer(i);</div><div class="line">    const string&amp; layer_name = layer_param.name();</div><div class="line">    CHECK(layer_param.include_size() == 0 || layer_param.exclude_size() == 0)</div><div class="line">          &lt;&lt; "Specify either include rules or exclude rules; not both.";</div><div class="line">    // If no include rules are specified, the layer is included by default and</div><div class="line">    // only excluded if it meets one of the exclude rules.</div><div class="line">    bool layer_included = (layer_param.include_size() == 0);</div><div class="line">    for (int j = 0; layer_included &amp;&amp; j &lt; layer_param.exclude_size(); ++j) &#123;</div><div class="line">      if (StateMeetsRule(net_state, layer_param.exclude(j), layer_name)) &#123;</div><div class="line">        layer_included = false;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    for (int j = 0; !layer_included &amp;&amp; j &lt; layer_param.include_size(); ++j) &#123;</div><div class="line">      if (StateMeetsRule(net_state, layer_param.include(j), layer_name)) &#123;</div><div class="line">        layer_included = true;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    if (layer_included) &#123;</div><div class="line">      param_filtered-&gt;add_layer()-&gt;CopyFrom(layer_param);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Init-函数"><a href="#Init-函数" class="headerlink" title="Init()函数"></a><code>Init()</code>函数</h2><ul>
<li>作用：使用<code>NetParameter</code>参数对网络进行初始化。</li>
<li>code 略长,很重要</li>
<li>分析技巧：每个<code>Net</code>由<code>Layer</code>类型的vector组成，每个<code>layer</code>都有对应的bottom vector输入和top vector输出，<br>所以一个<code>net</code>中有很多的<code>vector&lt;vector&lt;Blob&lt;Dtype&gt;*&gt;&gt;</code> 组成, 需要对其赋值操作细看。不明白的地方先看proto</li>
<li>主要的逻辑是对<code>Net</code>中一层一层进行初始化，解决每层的输入数据，参数设定等，计算需要的内存等</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::Init(<span class="keyword">const</span> NetParameter&amp; in_param) &#123;</div><div class="line">  CHECK(Caffe::root_solver() || root_net_)</div><div class="line">      &lt;&lt; <span class="string">"root_net_ needs to be set for all non-root solvers"</span>;</div><div class="line">  <span class="comment">// Set phase from the state.</span></div><div class="line">  phase_ = in_param.state().phase();</div><div class="line">  <span class="comment">// Filter layers based on their include/exclude rules and</span></div><div class="line">  <span class="comment">// the current NetState.</span></div><div class="line">  NetParameter filtered_param;</div><div class="line">  FilterNet(in_param, &amp;filtered_param);</div><div class="line">  LOG_IF(INFO, Caffe::root_solver())</div><div class="line">      &lt;&lt; <span class="string">"Initializing net from parameters: "</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span></div><div class="line">      &lt;&lt; filtered_param.DebugString();</div><div class="line">  <span class="comment">// Create a copy of filtered_param with splits added where necessary.</span></div><div class="line">  NetParameter param;</div><div class="line">  InsertSplits(filtered_param, &amp;param);</div><div class="line">  <span class="comment">// Basically, build all the layers and set up their connections.</span></div><div class="line">  name_ = param.name();</div><div class="line">  <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt; blob_name_to_idx;</div><div class="line">  <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt; available_blobs;</div><div class="line">  memory_used_ = <span class="number">0</span>;</div><div class="line">  <span class="comment">// For each layer, set up its input and output</span></div><div class="line">  bottom_vecs_.resize(param.layer_size());</div><div class="line">  top_vecs_.resize(param.layer_size());</div><div class="line">  bottom_id_vecs_.resize(param.layer_size());</div><div class="line">  param_id_vecs_.resize(param.layer_size());</div><div class="line">  top_id_vecs_.resize(param.layer_size());</div><div class="line">  bottom_need_backward_.resize(param.layer_size());</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> layer_id = <span class="number">0</span>; layer_id &lt; param.layer_size(); ++layer_id) &#123;</div><div class="line">    <span class="comment">// For non-root solvers, whether this layer is shared from root_net_.</span></div><div class="line">    <span class="keyword">bool</span> share_from_root = !Caffe::root_solver()</div><div class="line">        &amp;&amp; root_net_-&gt;layers_[layer_id]-&gt;ShareInParallel();</div><div class="line">    <span class="comment">// Inherit phase from net if unset.</span></div><div class="line">    <span class="keyword">if</span> (!param.layer(layer_id).has_phase()) &#123;</div><div class="line">      param.mutable_layer(layer_id)-&gt;set_phase(phase_);</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// Setup layer.</span></div><div class="line">    <span class="keyword">const</span> LayerParameter&amp; layer_param = param.layer(layer_id);</div><div class="line">    <span class="keyword">if</span> (layer_param.propagate_down_size() &gt; <span class="number">0</span>) &#123;</div><div class="line">      CHECK_EQ(layer_param.propagate_down_size(),</div><div class="line">          layer_param.bottom_size())</div><div class="line">          &lt;&lt; <span class="string">"propagate_down param must be specified "</span></div><div class="line">          &lt;&lt; <span class="string">"either 0 or bottom_size times "</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (share_from_root) &#123;</div><div class="line">      LOG(INFO) &lt;&lt; <span class="string">"Sharing layer "</span> &lt;&lt; layer_param.name() &lt;&lt; <span class="string">" from root net"</span>;</div><div class="line">      layers_.push_back(root_net_-&gt;layers_[layer_id]);</div><div class="line">      layers_[layer_id]-&gt;SetShared(<span class="literal">true</span>);</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      layers_.push_back(LayerRegistry&lt;Dtype&gt;::CreateLayer(layer_param));</div><div class="line">    &#125;</div><div class="line">    layer_names_.push_back(layer_param.name());</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"Creating Layer "</span> &lt;&lt; layer_param.name();</div><div class="line">    <span class="keyword">bool</span> need_backward = <span class="literal">false</span>;</div><div class="line"></div><div class="line">    <span class="comment">// Figure out this layer's input and output</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> bottom_id = <span class="number">0</span>; bottom_id &lt; layer_param.bottom_size();</div><div class="line">         ++bottom_id) &#123;</div><div class="line">      <span class="keyword">const</span> <span class="keyword">int</span> blob_id = AppendBottom(param, layer_id, bottom_id,</div><div class="line">                                       &amp;available_blobs, &amp;blob_name_to_idx);</div><div class="line">      <span class="comment">// If a blob needs backward, this layer should provide it.</span></div><div class="line">      need_backward |= blob_need_backward_[blob_id];</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">int</span> num_top = layer_param.top_size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> top_id = <span class="number">0</span>; top_id &lt; num_top; ++top_id) &#123;</div><div class="line">      AppendTop(param, layer_id, top_id, &amp;available_blobs, &amp;blob_name_to_idx);</div><div class="line">      <span class="comment">// Collect Input layer tops as Net inputs.</span></div><div class="line">      <span class="keyword">if</span> (layer_param.type() == <span class="string">"Input"</span>) &#123;</div><div class="line">        <span class="keyword">const</span> <span class="keyword">int</span> blob_id = blobs_.size() - <span class="number">1</span>;</div><div class="line">        net_input_blob_indices_.push_back(blob_id);</div><div class="line">        net_input_blobs_.push_back(blobs_[blob_id].get());</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// If the layer specifies that AutoTopBlobs() -&gt; true and the LayerParameter</span></div><div class="line">    <span class="comment">// specified fewer than the required number (as specified by</span></div><div class="line">    <span class="comment">// ExactNumTopBlobs() or MinTopBlobs()), allocate them here.</span></div><div class="line">    Layer&lt;Dtype&gt;* layer = layers_[layer_id].get();</div><div class="line">    <span class="keyword">if</span> (layer-&gt;AutoTopBlobs()) &#123;</div><div class="line">      <span class="keyword">const</span> <span class="keyword">int</span> needed_num_top =</div><div class="line">          <span class="built_in">std</span>::max(layer-&gt;MinTopBlobs(), layer-&gt;ExactNumTopBlobs());</div><div class="line">      <span class="keyword">for</span> (; num_top &lt; needed_num_top; ++num_top) &#123;</div><div class="line">        <span class="comment">// Add "anonymous" top blobs -- do not modify available_blobs or</span></div><div class="line">        <span class="comment">// blob_name_to_idx as we don't want these blobs to be usable as input</span></div><div class="line">        <span class="comment">// to other layers.</span></div><div class="line">        AppendTop(param, layer_id, num_top, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// After this layer is connected, set it up.</span></div><div class="line">    <span class="keyword">if</span> (share_from_root) &#123;</div><div class="line">      <span class="comment">// Set up size of top blobs using root_net_</span></div><div class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; base_top = root_net_-&gt;top_vecs_[layer_id];</div><div class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; this_top = <span class="keyword">this</span>-&gt;top_vecs_[layer_id];</div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> top_id = <span class="number">0</span>; top_id &lt; base_top.size(); ++top_id) &#123;</div><div class="line">        this_top[top_id]-&gt;ReshapeLike(*base_top[top_id]);</div><div class="line">        LOG(INFO) &lt;&lt; <span class="string">"Created top blob "</span> &lt;&lt; top_id &lt;&lt; <span class="string">" (shape: "</span></div><div class="line">            &lt;&lt; this_top[top_id]-&gt;shape_string() &lt;&lt;  <span class="string">") for shared layer "</span></div><div class="line">            &lt;&lt; layer_param.name();</div><div class="line">      &#125;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      layers_[layer_id]-&gt;SetUp(bottom_vecs_[layer_id], top_vecs_[layer_id]);</div><div class="line">    &#125;</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"Setting up "</span> &lt;&lt; layer_names_[layer_id];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> top_id = <span class="number">0</span>; top_id &lt; top_vecs_[layer_id].size(); ++top_id) &#123;</div><div class="line">      <span class="keyword">if</span> (blob_loss_weights_.size() &lt;= top_id_vecs_[layer_id][top_id]) &#123;</div><div class="line">        blob_loss_weights_.resize(top_id_vecs_[layer_id][top_id] + <span class="number">1</span>, Dtype(<span class="number">0</span>));</div><div class="line">      &#125;</div><div class="line">      blob_loss_weights_[top_id_vecs_[layer_id][top_id]] = layer-&gt;loss(top_id);</div><div class="line">      LOG_IF(INFO, Caffe::root_solver())</div><div class="line">          &lt;&lt; <span class="string">"Top shape: "</span> &lt;&lt; top_vecs_[layer_id][top_id]-&gt;shape_string();</div><div class="line">      <span class="keyword">if</span> (layer-&gt;loss(top_id)) &#123;</div><div class="line">        LOG_IF(INFO, Caffe::root_solver())</div><div class="line">            &lt;&lt; <span class="string">"    with loss weight "</span> &lt;&lt; layer-&gt;loss(top_id);</div><div class="line">      &#125;</div><div class="line">      memory_used_ += top_vecs_[layer_id][top_id]-&gt;count();</div><div class="line">    &#125;</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"Memory required for data: "</span> &lt;&lt; <span class="function">memory_used_ * <span class="title">sizeof</span><span class="params">(Dtype)</span></span>;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> param_size = layer_param.param_size();</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> num_param_blobs = layers_[layer_id]-&gt;blobs().size();</div><div class="line">    CHECK_LE(param_size, num_param_blobs)</div><div class="line">        &lt;&lt; <span class="string">"Too many params specified for layer "</span> &lt;&lt; layer_param.name();</div><div class="line">    ParamSpec default_param_spec;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> param_id = <span class="number">0</span>; param_id &lt; num_param_blobs; ++param_id) &#123;</div><div class="line">      <span class="keyword">const</span> ParamSpec* param_spec = (param_id &lt; param_size) ?</div><div class="line">          &amp;layer_param.param(param_id) : &amp;default_param_spec;</div><div class="line">      <span class="keyword">const</span> <span class="keyword">bool</span> param_need_backward = param_spec-&gt;lr_mult() != <span class="number">0</span>;</div><div class="line">      need_backward |= param_need_backward;</div><div class="line">      layers_[layer_id]-&gt;set_param_propagate_down(param_id,</div><div class="line">                                                  param_need_backward);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> param_id = <span class="number">0</span>; param_id &lt; num_param_blobs; ++param_id) &#123;</div><div class="line">      AppendParam(param, layer_id, param_id);</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// Finally, set the backward flag</span></div><div class="line">    layer_need_backward_.push_back(need_backward);</div><div class="line">    <span class="keyword">if</span> (need_backward) &#123;</div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> top_id = <span class="number">0</span>; top_id &lt; top_id_vecs_[layer_id].size(); ++top_id) &#123;</div><div class="line">        blob_need_backward_[top_id_vecs_[layer_id][top_id]] = <span class="literal">true</span>;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Go through the net backwards to determine which blobs contribute to the</span></div><div class="line">  <span class="comment">// loss.  We can skip backward computation for blobs that don't contribute</span></div><div class="line">  <span class="comment">// to the loss.</span></div><div class="line">  <span class="comment">// Also checks if all bottom blobs don't need backward computation (possible</span></div><div class="line">  <span class="comment">// because the skip_propagate_down param) and so we can skip bacward</span></div><div class="line">  <span class="comment">// computation for the entire layer</span></div><div class="line">  <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt; blobs_under_loss;</div><div class="line">  <span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt; blobs_skip_backp;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> layer_id = layers_.size() - <span class="number">1</span>; layer_id &gt;= <span class="number">0</span>; --layer_id) &#123;</div><div class="line">    <span class="keyword">bool</span> layer_contributes_loss = <span class="literal">false</span>;</div><div class="line">    <span class="keyword">bool</span> layer_skip_propagate_down = <span class="literal">true</span>;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> top_id = <span class="number">0</span>; top_id &lt; top_vecs_[layer_id].size(); ++top_id) &#123;</div><div class="line">      <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name = blob_names_[top_id_vecs_[layer_id][top_id]];</div><div class="line">      <span class="keyword">if</span> (layers_[layer_id]-&gt;loss(top_id) ||</div><div class="line">          (blobs_under_loss.find(blob_name) != blobs_under_loss.end())) &#123;</div><div class="line">        layer_contributes_loss = <span class="literal">true</span>;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (blobs_skip_backp.find(blob_name) == blobs_skip_backp.end()) &#123;</div><div class="line">        layer_skip_propagate_down = <span class="literal">false</span>;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (layer_contributes_loss &amp;&amp; !layer_skip_propagate_down)</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// If this layer can skip backward computation, also all his bottom blobs</span></div><div class="line">    <span class="comment">// don't need backpropagation</span></div><div class="line">    <span class="keyword">if</span> (layer_need_backward_[layer_id] &amp;&amp; layer_skip_propagate_down) &#123;</div><div class="line">      layer_need_backward_[layer_id] = <span class="literal">false</span>;</div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> bottom_id = <span class="number">0</span>; bottom_id &lt; bottom_vecs_[layer_id].size();</div><div class="line">               ++bottom_id) &#123;</div><div class="line">        bottom_need_backward_[layer_id][bottom_id] = <span class="literal">false</span>;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (!layer_contributes_loss) &#123; layer_need_backward_[layer_id] = <span class="literal">false</span>; &#125;</div><div class="line">    <span class="keyword">if</span> (Caffe::root_solver()) &#123;</div><div class="line">      <span class="keyword">if</span> (layer_need_backward_[layer_id]) &#123;</div><div class="line">        LOG(INFO) &lt;&lt; layer_names_[layer_id] &lt;&lt; <span class="string">" needs backward computation."</span>;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        LOG(INFO) &lt;&lt; layer_names_[layer_id]</div><div class="line">            &lt;&lt; <span class="string">" does not need backward computation."</span>;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> bottom_id = <span class="number">0</span>; bottom_id &lt; bottom_vecs_[layer_id].size();</div><div class="line">         ++bottom_id) &#123;</div><div class="line">      <span class="keyword">if</span> (layer_contributes_loss) &#123;</div><div class="line">        <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name =</div><div class="line">            blob_names_[bottom_id_vecs_[layer_id][bottom_id]];</div><div class="line">        blobs_under_loss.insert(blob_name);</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">        bottom_need_backward_[layer_id][bottom_id] = <span class="literal">false</span>;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (!bottom_need_backward_[layer_id][bottom_id]) &#123;</div><div class="line">        <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name =</div><div class="line">                   blob_names_[bottom_id_vecs_[layer_id][bottom_id]];</div><div class="line">        blobs_skip_backp.insert(blob_name);</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Handle force_backward if needed.</span></div><div class="line">  <span class="keyword">if</span> (param.force_backward()) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> layer_id = <span class="number">0</span>; layer_id &lt; layers_.size(); ++layer_id) &#123;</div><div class="line">      layer_need_backward_[layer_id] = <span class="literal">true</span>;</div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> bottom_id = <span class="number">0</span>;</div><div class="line">           bottom_id &lt; bottom_need_backward_[layer_id].size(); ++bottom_id) &#123;</div><div class="line">        bottom_need_backward_[layer_id][bottom_id] =</div><div class="line">            bottom_need_backward_[layer_id][bottom_id] ||</div><div class="line">            layers_[layer_id]-&gt;AllowForceBackward(bottom_id);</div><div class="line">        blob_need_backward_[bottom_id_vecs_[layer_id][bottom_id]] =</div><div class="line">            blob_need_backward_[bottom_id_vecs_[layer_id][bottom_id]] ||</div><div class="line">            bottom_need_backward_[layer_id][bottom_id];</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> param_id = <span class="number">0</span>; param_id &lt; layers_[layer_id]-&gt;blobs().size();</div><div class="line">           ++param_id) &#123;</div><div class="line">        layers_[layer_id]-&gt;set_param_propagate_down(param_id, <span class="literal">true</span>);</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// In the end, all remaining blobs are considered output blobs.</span></div><div class="line">  <span class="keyword">for</span> (<span class="built_in">set</span>&lt;<span class="built_in">string</span>&gt;::iterator it = available_blobs.begin();</div><div class="line">      it != available_blobs.end(); ++it) &#123;</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"This network produces output "</span> &lt;&lt; *it;</div><div class="line">    net_output_blobs_.push_back(blobs_[blob_name_to_idx[*it]].get());</div><div class="line">    net_output_blob_indices_.push_back(blob_name_to_idx[*it]);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> blob_id = <span class="number">0</span>; blob_id &lt; blob_names_.size(); ++blob_id) &#123;</div><div class="line">    blob_names_index_[blob_names_[blob_id]] = blob_id;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> layer_id = <span class="number">0</span>; layer_id &lt; layer_names_.size(); ++layer_id) &#123;</div><div class="line">    layer_names_index_[layer_names_[layer_id]] = layer_id;</div><div class="line">  &#125;</div><div class="line">  ShareWeights();</div><div class="line">  debug_info_ = param.debug_info();</div><div class="line">  LOG_IF(INFO, Caffe::root_solver()) &lt;&lt; <span class="string">"Network initialization done."</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="StateMeetsRule"><a href="#StateMeetsRule" class="headerlink" title="StateMeetsRule"></a><code>StateMeetsRule</code></h2><p>网络中每层的状态检查函数</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">bool</span> Net&lt;Dtype&gt;::StateMeetsRule(<span class="keyword">const</span> NetState&amp; state,</div><div class="line">    <span class="keyword">const</span> NetStateRule&amp; rule, <span class="keyword">const</span> <span class="built_in">string</span>&amp; layer_name) &#123;</div><div class="line">  <span class="comment">// Check whether the rule is broken due to phase.</span></div><div class="line">  <span class="keyword">if</span> (rule.has_phase()) &#123;</div><div class="line">      <span class="keyword">if</span> (rule.phase() != state.phase()) &#123;</div><div class="line">        LOG_IF(INFO, Caffe::root_solver())</div><div class="line">            &lt;&lt; <span class="string">"The NetState phase ("</span> &lt;&lt; state.phase()</div><div class="line">            &lt;&lt; <span class="string">") differed from the phase ("</span> &lt;&lt; rule.phase()</div><div class="line">            &lt;&lt; <span class="string">") specified by a rule in layer "</span> &lt;&lt; layer_name;</div><div class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Check whether the rule is broken due to min level.</span></div><div class="line">  <span class="keyword">if</span> (rule.has_min_level()) &#123;</div><div class="line">    <span class="keyword">if</span> (state.level() &lt; rule.min_level()) &#123;</div><div class="line">      LOG_IF(INFO, Caffe::root_solver())</div><div class="line">          &lt;&lt; <span class="string">"The NetState level ("</span> &lt;&lt; state.level()</div><div class="line">          &lt;&lt; <span class="string">") is above the min_level ("</span> &lt;&lt; rule.min_level()</div><div class="line">          &lt;&lt; <span class="string">") specified by a rule in layer "</span> &lt;&lt; layer_name;</div><div class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Check whether the rule is broken due to max level.</span></div><div class="line">  <span class="keyword">if</span> (rule.has_max_level()) &#123;</div><div class="line">    <span class="keyword">if</span> (state.level() &gt; rule.max_level()) &#123;</div><div class="line">      LOG_IF(INFO, Caffe::root_solver())</div><div class="line">          &lt;&lt; <span class="string">"The NetState level ("</span> &lt;&lt; state.level()</div><div class="line">          &lt;&lt; <span class="string">") is above the max_level ("</span> &lt;&lt; rule.max_level()</div><div class="line">          &lt;&lt; <span class="string">") specified by a rule in layer "</span> &lt;&lt; layer_name;</div><div class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Check whether the rule is broken due to stage. The NetState must</span></div><div class="line">  <span class="comment">// contain ALL of the rule's stages to meet it.</span></div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rule.stage_size(); ++i) &#123;</div><div class="line">    <span class="comment">// Check that the NetState contains the rule's ith stage.</span></div><div class="line">    <span class="keyword">bool</span> has_stage = <span class="literal">false</span>;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; !has_stage &amp;&amp; j &lt; state.stage_size(); ++j) &#123;</div><div class="line">      <span class="keyword">if</span> (rule.stage(i) == state.stage(j)) &#123; has_stage = <span class="literal">true</span>; &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (!has_stage) &#123;</div><div class="line">      LOG_IF(INFO, Caffe::root_solver())</div><div class="line">          &lt;&lt; <span class="string">"The NetState did not contain stage '"</span> &lt;&lt; rule.stage(i)</div><div class="line">          &lt;&lt; <span class="string">"' specified by a rule in layer "</span> &lt;&lt; layer_name;</div><div class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Check whether the rule is broken due to not_stage. The NetState must</span></div><div class="line">  <span class="comment">// contain NONE of the rule's not_stages to meet it.</span></div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rule.not_stage_size(); ++i) &#123;</div><div class="line">    <span class="comment">// Check that the NetState contains the rule's ith not_stage.</span></div><div class="line">    <span class="keyword">bool</span> has_stage = <span class="literal">false</span>;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; !has_stage &amp;&amp; j &lt; state.stage_size(); ++j) &#123;</div><div class="line">      <span class="keyword">if</span> (rule.not_stage(i) == state.stage(j)) &#123; has_stage = <span class="literal">true</span>; &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (has_stage) &#123;</div><div class="line">      LOG_IF(INFO, Caffe::root_solver())</div><div class="line">          &lt;&lt; <span class="string">"The NetState contained a not_stage '"</span> &lt;&lt; rule.not_stage(i)</div><div class="line">          &lt;&lt; <span class="string">"' specified by a rule in layer "</span> &lt;&lt; layer_name;</div><div class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Net中的前向函数"><a href="#Net中的前向函数" class="headerlink" title="Net中的前向函数"></a>Net中的前向函数</h2><p>网络中层之间的前向函数，指定start和end,返回的是经过的层之间的loss<br>具体是对每层调用Forward</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line">Dtype Net&lt;Dtype&gt;::ForwardFromTo(<span class="keyword">int</span> start, <span class="keyword">int</span> end) &#123;</div><div class="line">  CHECK_GE(start, <span class="number">0</span>);</div><div class="line">  CHECK_LT(end, layers_.size());</div><div class="line">  Dtype loss = <span class="number">0</span>;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt;= end; ++i) &#123;</div><div class="line">    <span class="comment">// LOG(ERROR) &lt;&lt; "Forwarding " &lt;&lt; layer_names_[i];</span></div><div class="line">    Dtype layer_loss = layers_[i]-&gt;Forward(bottom_vecs_[i], top_vecs_[i]);</div><div class="line">    loss += layer_loss;</div><div class="line">    <span class="keyword">if</span> (debug_info_) &#123; ForwardDebugInfo(i); &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> loss;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line">Dtype Net&lt;Dtype&gt;::ForwardFrom(<span class="keyword">int</span> start) &#123;</div><div class="line">  <span class="keyword">return</span> ForwardFromTo(start, layers_.size() - <span class="number">1</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line">Dtype Net&lt;Dtype&gt;::ForwardTo(<span class="keyword">int</span> end) &#123;</div><div class="line">  <span class="keyword">return</span> ForwardFromTo(<span class="number">0</span>, end);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; Net&lt;Dtype&gt;::Forward(Dtype* loss) &#123;</div><div class="line">  <span class="keyword">if</span> (loss != <span class="literal">NULL</span>) &#123;</div><div class="line">    *loss = ForwardFromTo(<span class="number">0</span>, layers_.size() - <span class="number">1</span>);</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    ForwardFromTo(<span class="number">0</span>, layers_.size() - <span class="number">1</span>);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> net_output_blobs_;</div><div class="line">&#125;</div><div class="line"></div><div class="line">``` </div><div class="line"></div><div class="line">## Net中的反向传播函数</div><div class="line">对每层调用Backward</div><div class="line"> </div><div class="line">```cpp</div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::BackwardFromTo(<span class="keyword">int</span> start, <span class="keyword">int</span> end) &#123;</div><div class="line">  CHECK_GE(end, <span class="number">0</span>);</div><div class="line">  CHECK_LT(start, layers_.size());</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &gt;= end; --i) &#123;</div><div class="line">    <span class="keyword">if</span> (layer_need_backward_[i]) &#123;</div><div class="line">      layers_[i]-&gt;Backward(</div><div class="line">          top_vecs_[i], bottom_need_backward_[i], bottom_vecs_[i]);</div><div class="line">      <span class="keyword">if</span> (debug_info_) &#123; BackwardDebugInfo(i); &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::BackwardFrom(<span class="keyword">int</span> start) &#123;</div><div class="line">  BackwardFromTo(start, <span class="number">0</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::BackwardTo(<span class="keyword">int</span> end) &#123;</div><div class="line">  BackwardFromTo(layers_.size() - <span class="number">1</span>, end);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::Backward() &#123;</div><div class="line">  BackwardFromTo(layers_.size() - <span class="number">1</span>, <span class="number">0</span>);</div><div class="line">  <span class="keyword">if</span> (debug_info_) &#123;</div><div class="line">    Dtype asum_data = <span class="number">0</span>, asum_diff = <span class="number">0</span>, sumsq_data = <span class="number">0</span>, sumsq_diff = <span class="number">0</span>;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; learnable_params_.size(); ++i) &#123;</div><div class="line">      asum_data += learnable_params_[i]-&gt;asum_data();</div><div class="line">      asum_diff += learnable_params_[i]-&gt;asum_diff();</div><div class="line">      sumsq_data += learnable_params_[i]-&gt;sumsq_data();</div><div class="line">      sumsq_diff += learnable_params_[i]-&gt;sumsq_diff();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">const</span> Dtype l2norm_data = <span class="built_in">std</span>::<span class="built_in">sqrt</span>(sumsq_data);</div><div class="line">    <span class="keyword">const</span> Dtype l2norm_diff = <span class="built_in">std</span>::<span class="built_in">sqrt</span>(sumsq_diff);</div><div class="line">    LOG(ERROR) &lt;&lt; <span class="string">"    [Backward] All net params (data, diff): "</span></div><div class="line">               &lt;&lt; <span class="string">"L1 norm = ("</span> &lt;&lt; asum_data &lt;&lt; <span class="string">", "</span> &lt;&lt; asum_diff &lt;&lt; <span class="string">"); "</span></div><div class="line">               &lt;&lt; <span class="string">"L2 norm = ("</span> &lt;&lt; l2norm_data &lt;&lt; <span class="string">", "</span> &lt;&lt; l2norm_diff &lt;&lt; <span class="string">")"</span>;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Reshape"><a href="#Reshape" class="headerlink" title="Reshape"></a><code>Reshape</code></h2><p>对网络中每层调用Reshape</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::Reshape() &#123;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; layers_.size(); ++i) &#123;</div><div class="line">    layers_[i]-&gt;Reshape(bottom_vecs_[i], top_vecs_[i]);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Debug信息打印函数"><a href="#Debug信息打印函数" class="headerlink" title="Debug信息打印函数"></a>Debug信息打印函数</h2><p>在网络前向，反向和更新时打印信息</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::ForwardDebugInfo(<span class="keyword">const</span> <span class="keyword">int</span> layer_id) &#123;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> top_id = <span class="number">0</span>; top_id &lt; top_vecs_[layer_id].size(); ++top_id) &#123;</div><div class="line">    <span class="keyword">const</span> Blob&lt;Dtype&gt;&amp; blob = *top_vecs_[layer_id][top_id];</div><div class="line">    <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name = blob_names_[top_id_vecs_[layer_id][top_id]];</div><div class="line">    <span class="keyword">const</span> Dtype data_abs_val_mean = blob.asum_data() / blob.count();</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"    [Forward] "</span></div><div class="line">        &lt;&lt; <span class="string">"Layer "</span> &lt;&lt; layer_names_[layer_id]</div><div class="line">        &lt;&lt; <span class="string">", top blob "</span> &lt;&lt; blob_name</div><div class="line">        &lt;&lt; <span class="string">" data: "</span> &lt;&lt; data_abs_val_mean;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> param_id = <span class="number">0</span>; param_id &lt; layers_[layer_id]-&gt;blobs().size();</div><div class="line">       ++param_id) &#123;</div><div class="line">    <span class="keyword">const</span> Blob&lt;Dtype&gt;&amp; blob = *layers_[layer_id]-&gt;blobs()[param_id];</div><div class="line">    <span class="keyword">const</span> <span class="keyword">int</span> net_param_id = param_id_vecs_[layer_id][param_id];</div><div class="line">    <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name = param_display_names_[net_param_id];</div><div class="line">    <span class="keyword">const</span> Dtype data_abs_val_mean = blob.asum_data() / blob.count();</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"    [Forward] "</span></div><div class="line">        &lt;&lt; <span class="string">"Layer "</span> &lt;&lt; layer_names_[layer_id]</div><div class="line">        &lt;&lt; <span class="string">", param blob "</span> &lt;&lt; blob_name</div><div class="line">        &lt;&lt; <span class="string">" data: "</span> &lt;&lt; data_abs_val_mean;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::BackwardDebugInfo(<span class="keyword">const</span> <span class="keyword">int</span> layer_id) &#123;</div><div class="line">  <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom_vec = bottom_vecs_[layer_id];</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> bottom_id = <span class="number">0</span>; bottom_id &lt; bottom_vec.size(); ++bottom_id) &#123;</div><div class="line">    <span class="keyword">if</span> (!bottom_need_backward_[layer_id][bottom_id]) &#123; <span class="keyword">continue</span>; &#125;</div><div class="line">    <span class="keyword">const</span> Blob&lt;Dtype&gt;&amp; blob = *bottom_vec[bottom_id];</div><div class="line">    <span class="keyword">const</span> <span class="built_in">string</span>&amp; blob_name = blob_names_[bottom_id_vecs_[layer_id][bottom_id]];</div><div class="line">    <span class="keyword">const</span> Dtype diff_abs_val_mean = blob.asum_diff() / blob.count();</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"    [Backward] "</span></div><div class="line">        &lt;&lt; <span class="string">"Layer "</span> &lt;&lt; layer_names_[layer_id]</div><div class="line">        &lt;&lt; <span class="string">", bottom blob "</span> &lt;&lt; blob_name</div><div class="line">        &lt;&lt; <span class="string">" diff: "</span> &lt;&lt; diff_abs_val_mean;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> param_id = <span class="number">0</span>; param_id &lt; layers_[layer_id]-&gt;blobs().size();</div><div class="line">       ++param_id) &#123;</div><div class="line">    <span class="keyword">if</span> (!layers_[layer_id]-&gt;param_propagate_down(param_id)) &#123; <span class="keyword">continue</span>; &#125;</div><div class="line">    <span class="keyword">const</span> Blob&lt;Dtype&gt;&amp; blob = *layers_[layer_id]-&gt;blobs()[param_id];</div><div class="line">    <span class="keyword">const</span> Dtype diff_abs_val_mean = blob.asum_diff() / blob.count();</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"    [Backward] "</span></div><div class="line">        &lt;&lt; <span class="string">"Layer "</span> &lt;&lt; layer_names_[layer_id]</div><div class="line">        &lt;&lt; <span class="string">", param blob "</span> &lt;&lt; param_id</div><div class="line">        &lt;&lt; <span class="string">" diff: "</span> &lt;&lt; diff_abs_val_mean;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</div><div class="line"><span class="keyword">void</span> Net&lt;Dtype&gt;::UpdateDebugInfo(<span class="keyword">const</span> <span class="keyword">int</span> param_id) &#123;</div><div class="line">  <span class="keyword">const</span> Blob&lt;Dtype&gt;&amp; blob = *params_[param_id];</div><div class="line">  <span class="keyword">const</span> <span class="keyword">int</span> param_owner = param_owners_[param_id];</div><div class="line">  <span class="keyword">const</span> <span class="built_in">string</span>&amp; layer_name = layer_names_[param_layer_indices_[param_id].first];</div><div class="line">  <span class="keyword">const</span> <span class="built_in">string</span>&amp; param_display_name = param_display_names_[param_id];</div><div class="line">  <span class="keyword">const</span> Dtype diff_abs_val_mean = blob.asum_diff() / blob.count();</div><div class="line">  <span class="keyword">if</span> (param_owner &lt; <span class="number">0</span>) &#123;</div><div class="line">    <span class="keyword">const</span> Dtype data_abs_val_mean = blob.asum_data() / blob.count();</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"    [Update] Layer "</span> &lt;&lt; layer_name</div><div class="line">        &lt;&lt; <span class="string">", param "</span> &lt;&lt; param_display_name</div><div class="line">        &lt;&lt; <span class="string">" data: "</span> &lt;&lt; data_abs_val_mean</div><div class="line">        &lt;&lt; <span class="string">"; diff: "</span> &lt;&lt; diff_abs_val_mean;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    <span class="keyword">const</span> <span class="built_in">string</span>&amp; owner_layer_name =</div><div class="line">        layer_names_[param_layer_indices_[param_owner].first];</div><div class="line">    LOG_IF(INFO, Caffe::root_solver())</div><div class="line">        &lt;&lt; <span class="string">"    [Update] Layer "</span> &lt;&lt; layer_name</div><div class="line">        &lt;&lt; <span class="string">", param blob "</span> &lt;&lt; param_display_name</div><div class="line">        &lt;&lt; <span class="string">" (owned by layer "</span> &lt;&lt; owner_layer_name &lt;&lt; <span class="string">", "</span> &lt;&lt; <span class="string">"param "</span></div><div class="line">        &lt;&lt; param_display_names_[param_owners_[param_id]] &lt;&lt; <span class="string">")"</span></div><div class="line">        &lt;&lt; <span class="string">" diff: "</span> &lt;&lt; diff_abs_val_mean;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="从其他网络复制层"><a href="#从其他网络复制层" class="headerlink" title="从其他网络复制层"></a>从其他网络复制层</h2><ul>
<li><code>ShareTrainedLayersWith</code></li>
<li><code>CopyTrainedLayersFrom(const NetParameter&amp; param)</code></li>
<li><code>CopyTrainedLayersFrom(const string trained_filename)</code></li>
<li><code>CopyTrainedLayersFromBinaryProto()</code></li>
<li><code>CopyTrainedLayersFromHDF5</code></li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">**</div><div class="line">   * @brief For an already initialized net, implicitly copies (i.e., using no</div><div class="line">   *        additional memory) the pre-trained layers from another Net.</div><div class="line">   */</div><div class="line">  void ShareTrainedLayersWith(const Net* other);</div><div class="line">  // For an already initialized net, CopyTrainedLayersFrom() copies the already</div><div class="line">  // trained layers from another net parameter instance.</div><div class="line">  /**</div><div class="line">   * @brief For an already initialized net, copies the pre-trained layers from</div><div class="line">   *        another Net.</div><div class="line">   */</div><div class="line">  void CopyTrainedLayersFrom(const NetParameter&amp; param);</div><div class="line">  void CopyTrainedLayersFrom(const string trained_filename);</div><div class="line">  void CopyTrainedLayersFromBinaryProto(const string trained_filename);</div><div class="line">  void CopyTrainedLayersFromHDF5(const string trained_filename);</div></pre></td></tr></table></figure>
<h2 id="写到proto或者hdf5"><a href="#写到proto或者hdf5" class="headerlink" title="写到proto或者hdf5"></a>写到proto或者hdf5</h2><ul>
<li><code>ToProto(NetParameter* param, bool write_diff)</code></li>
<li><code>ToHDF5(const string&amp; filename, bool write_diff)</code></li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/// @brief Writes the net to a proto.</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">ToProto</span><span class="params">(NetParameter* param, <span class="keyword">bool</span> write_diff = <span class="literal">false</span>)</span> <span class="keyword">const</span></span>;</div><div class="line"><span class="comment">/// @brief Writes the net to an HDF5 file.</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">ToHDF5</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; filename, <span class="keyword">bool</span> write_diff = <span class="literal">false</span>)</span> <span class="keyword">const</span></span>;</div></pre></td></tr></table></figure>
<h2 id="其他的一些Get函数"><a href="#其他的一些Get函数" class="headerlink" title="其他的一些Get函数"></a>其他的一些Get函数</h2><p>简单的Get函数一般都是内联函数，用来获取定义的保护变量.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/// @brief returns the network name.</span></div><div class="line">  <span class="function"><span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">string</span>&amp; <span class="title">name</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> name_; &#125;</div><div class="line">  <span class="comment">/// @brief returns the layer names</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; layer_names() <span class="keyword">const</span> &#123; <span class="keyword">return</span> layer_names_; &#125;</div><div class="line">  <span class="comment">/// @brief returns the blob names</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; blob_names() <span class="keyword">const</span> &#123; <span class="keyword">return</span> blob_names_; &#125;</div><div class="line">  <span class="comment">/// @brief returns the blobs</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;Blob&lt;Dtype&gt; &gt; &gt;&amp; blobs() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> blobs_;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/// @brief returns the layers</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;Layer&lt;Dtype&gt; &gt; &gt;&amp; layers() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> layers_;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/// @brief returns the phase: TRAIN or TEST</span></div><div class="line">  <span class="function"><span class="keyword">inline</span> Phase <span class="title">phase</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> phase_; &#125;</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * @brief returns the bottom vecs for each layer -- usually you won't</div><div class="line">   *        need this unless you do per-layer checks such as gradients.</div><div class="line">   */</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; &gt;&amp; bottom_vecs() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> bottom_vecs_;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/**</span></div><div class="line">   * @brief returns the top vecs for each layer -- usually you won't</div><div class="line">   *        need this unless you do per-layer checks such as gradients.</div><div class="line">   */</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt; &gt;&amp; top_vecs() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> top_vecs_;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/// @brief returns the ids of the top blobs of layer i</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp; top_ids(<span class="keyword">int</span> i) <span class="keyword">const</span> &#123;</div><div class="line">    CHECK_GE(i, <span class="number">0</span>) &lt;&lt; <span class="string">"Invalid layer id"</span>;</div><div class="line">    CHECK_LT(i, top_id_vecs_.size()) &lt;&lt; <span class="string">"Invalid layer id"</span>;</div><div class="line">    <span class="keyword">return</span> top_id_vecs_[i];</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/// @brief returns the ids of the bottom blobs of layer i</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &amp; bottom_ids(<span class="keyword">int</span> i) <span class="keyword">const</span> &#123;</div><div class="line">    CHECK_GE(i, <span class="number">0</span>) &lt;&lt; <span class="string">"Invalid layer id"</span>;</div><div class="line">    CHECK_LT(i, bottom_id_vecs_.size()) &lt;&lt; <span class="string">"Invalid layer id"</span>;</div><div class="line">    <span class="keyword">return</span> bottom_id_vecs_[i];</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; &gt;&amp; bottom_need_backward() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> bottom_need_backward_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Dtype&gt;&amp; blob_loss_weights() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> blob_loss_weights_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; layer_need_backward() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> layer_need_backward_;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/// @brief returns the parameters</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">shared_ptr</span>&lt;Blob&lt;Dtype&gt; &gt; &gt;&amp; params() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> params_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; learnable_params() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> learnable_params_;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/// @brief returns the learnable parameter learning rate multipliers</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt;&amp; params_lr() <span class="keyword">const</span> &#123; <span class="keyword">return</span> params_lr_; &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; has_params_lr() <span class="keyword">const</span> &#123; <span class="keyword">return</span> has_params_lr_; &#125;</div><div class="line">  <span class="comment">/// @brief returns the learnable parameter decay multipliers</span></div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt;&amp; params_weight_decay() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> params_weight_decay_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; has_params_decay() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> has_params_decay_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">const</span> <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;&amp; param_names_index() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> param_names_index_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; param_owners() <span class="keyword">const</span> &#123; <span class="keyword">return</span> param_owners_; &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; param_display_names() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> param_display_names_;</div><div class="line">  &#125;</div><div class="line">  <span class="comment">/// @brief Input and output blob numbers</span></div><div class="line">  <span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">num_inputs</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> net_input_blobs_.size(); &#125;</div><div class="line">  <span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">num_outputs</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> net_output_blobs_.size(); &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; input_blobs() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> net_input_blobs_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; output_blobs() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> net_output_blobs_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; input_blob_indices() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> net_input_blob_indices_;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">inline</span> <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; output_blob_indices() <span class="keyword">const</span> &#123;</div><div class="line">    <span class="keyword">return</span> net_output_blob_indices_;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><code>Net</code>会比<code>Layer</code>的代码复杂度稍微高一些，主要也是对一个net中的每个layer去做初始化操作，所以具体操作都是在layer上做的。重要的是<code>Init()</code>初始化函数，构造函数用它来初始化一个网络，net的<code>Forwward</code>和<code>Backward</code>其实就是调用了其中每个层的<code>Forward</code>和<code>Backward</code>。其中还有一些重要的函数是从已经训练好的网络，来根据layer的名字复制对应的内容，这个操作是比较重要的，因为模型的finetune都与此有关。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/07/01/Caffe解读5-Layer/" rel="next" title="Caffe解读5 -- Layer">
                <i class="fa fa-chevron-left"></i> Caffe解读5 -- Layer
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/08/19/VGG训练ImageNet/" rel="prev" title="VGG训练ImageNet">
                VGG训练ImageNet <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="fb-comments"
           data-href="http://yoursite.com/2016/07/10/Caffe解读6-Net/"
           data-numposts="10"
           data-width="100%"
           data-colorscheme="light">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="John Doe" />
          <p class="site-author-name" itemprop="name">John Doe</p>
          <p class="site-description motion-element" itemprop="description">Stay hungry</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">12</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#简介"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#message-NetParameter"><span class="nav-number">2.</span> <span class="nav-text">message NetParameter</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#具体实现"><span class="nav-number">3.</span> <span class="nav-text">具体实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#protected变量"><span class="nav-number">3.1.</span> <span class="nav-text">protected变量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#protected-方法"><span class="nav-number">3.2.</span> <span class="nav-text">protected 方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#AppendTop"><span class="nav-number">3.2.1.</span> <span class="nav-text">AppendTop()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AppendBottom"><span class="nav-number">3.2.2.</span> <span class="nav-text">AppendBottom()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AppendParam"><span class="nav-number">3.2.3.</span> <span class="nav-text">AppendParam()</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构造函数"><span class="nav-number">3.3.</span> <span class="nav-text">构造函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FilterNet-函数"><span class="nav-number">3.4.</span> <span class="nav-text">FilterNet()函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Init-函数"><span class="nav-number">3.5.</span> <span class="nav-text">Init()函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#StateMeetsRule"><span class="nav-number">3.6.</span> <span class="nav-text">StateMeetsRule</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Net中的前向函数"><span class="nav-number">3.7.</span> <span class="nav-text">Net中的前向函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reshape"><span class="nav-number">3.8.</span> <span class="nav-text">Reshape</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Debug信息打印函数"><span class="nav-number">3.9.</span> <span class="nav-text">Debug信息打印函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#从其他网络复制层"><span class="nav-number">3.10.</span> <span class="nav-text">从其他网络复制层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#写到proto或者hdf5"><span class="nav-number">3.11.</span> <span class="nav-text">写到proto或者hdf5</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他的一些Get函数"><span class="nav-number">3.12.</span> <span class="nav-text">其他的一些Get函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>







        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	




  
  

  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("", "");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



</body>
</html>
